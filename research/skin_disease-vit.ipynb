{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skin Disease Classification using Vision Transformer (ViT)\n",
    "\n",
    "This notebook implements skin disease classification using the Vision Transformer architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Vision Transformer Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = tf.keras.layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "class Patches(tf.keras.layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches\n",
    "\n",
    "class PatchEncoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super().__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = tf.keras.layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = tf.keras.layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build ViT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_classifier():\n",
    "    input_shape = (224, 224, 3)\n",
    "    patch_size = 16\n",
    "    num_patches = (input_shape[0] // patch_size) * (input_shape[1] // patch_size)\n",
    "    projection_dim = 64\n",
    "    num_heads = 4\n",
    "    transformer_units = [projection_dim * 2, projection_dim]\n",
    "    transformer_layers = 8\n",
    "    mlp_head_units = [2048, 1024]\n",
    "    num_classes = 7\n",
    "\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "    patches = Patches(patch_size)(inputs)\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    for _ in range(transformer_layers):\n",
    "        x1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        attention_output = tf.keras.layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        x2 = tf.keras.layers.Add()([attention_output, encoded_patches])\n",
    "        x3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        encoded_patches = tf.keras.layers.Add()([x3, x2])\n",
    "\n",
    "    representation = tf.keras.layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = tf.keras.layers.Flatten()(representation)\n",
    "    representation = tf.keras.layers.Dropout(0.3)(representation)\n",
    "\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.3)\n",
    "    logits = tf.keras.layers.Dense(num_classes)(features)\n",
    "    outputs = tf.keras.layers.Activation('softmax')(logits)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Model compilation\n",
    "model = create_vit_classifier()\n",
    "optimizer = tfa.optimizers.AdamW(\n",
    "    learning_rate=3e-4,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model_vit.h5',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Attention Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_maps(model, image, layer_name):\n",
    "    attention_layer = model.get_layer(layer_name)\n",
    "    attention_model = tf.keras.Model(\n",
    "        inputs=model.input,\n",
    "        outputs=attention_layer.output\n",
    "    )\n",
    "    \n",
    "    attention_output = attention_model.predict(image)\n",
    "    attention_weights = attention_output[1]  # Get attention weights\n",
    "    \n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.imshow(attention_weights[0], cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    plt.title(f'Attention Map from {layer_name}')\n",
    "    plt.show()\n",
    "\n",
    "def visualize_predictions(model, images, true_labels, class_names):\n",
    "    predictions = model.predict(images)\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i in range(min(5, len(images))):\n",
    "        plt.subplot(1, 5, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(f'True: {class_names[true_labels[i]]}\\nPred: {class_names[np.argmax(predictions[i])]}')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model saving directory\n",
    "model_save_dir = os.path.join('..', 'models', 'vit')\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "# Update checkpoint callback\n",
    "checkpoint = ModelCheckpoint(\n",
    "    os.path.join(model_save_dir, 'best_model_vit.h5'),\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "# Add model saving after training\n",
    "model.save(os.path.join(model_save_dir, 'final_model_vit.h5'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
